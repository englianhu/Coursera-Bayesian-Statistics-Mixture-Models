---
title: "<img src='figure/coursera.jpg' width='37'> <img src='figure/ucsc.png' width='240'>"
subtitle: "<span style='color:white; background-color:#4E79A7;'>Bayesian Statistics: Mixture Models</span> (Assessment Week3 with Codes)"
author: "[Â®Î³Ïƒ, Lian Hu](https://englianhu.github.io/) <img src='figure/quantitative trader 1.jpg' width='12'> <img src='figure/ENG.jpg' width='24'> Â®"
date: "`r lubridate::today('Asia/Tokyo')`"
output:
  html_document: 
    mathjax: https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    code_folding: hide
    css: CSSBackgrounds.css
---

<br>
<span style='color:green'>**Theme Song**</span>
<br>

<audio src="music/California-Dreaming-Chorus.mp3" controls></audio>
<br>

------

## SCSS Setup

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

```{r class.source = 'bg-success', class.output = 'bg-primary', message = FALSE, warning = FALSE}
# install.packages("remotes")
require('BBmisc')
#remotes::install_github("rstudio/sass")
lib('sass')
```

```{scss class.source = 'bg-success', class.output = 'bg-primary'}
/* https://stackoverflow.com/a/66029010/3806250 */
h1 { color: #002C54; }
h2 { color: #2F496E; }
h3 { color: #375E97; }

/* ----------------------------------------------------------------- */
/* https://gist.github.com/himynameisdave/c7a7ed14500d29e58149#file-broken-gradient-animation-less */
.hover-animate-background1 {
  /* color: #FFD64D; */
  background: linear-gradient(155deg, #EDAE01 0%, #FFEB94 100%);
  transition: all 0.45s;
  &:hover{
    background: linear-gradient(155deg, #EDAE01 20%, #FFEB94 80%);
    }
  }

/* //  For brevity, vendor prefixes have been removed. */
/* //  This does not work as expected; instead of a smooth transition */
/* //  what you get is a hard swap from one gradient to the next */
.hover-animate-background2 {
  color: #FFD64D;
  background: linear-gradient(155deg, #002C54 0%, #4CB5F5 100%);
  transition: all 0.45s;
  &:hover{
    background: linear-gradient(155deg, #002C54 20%, #4CB5F5 80%);
    }
  }
```

```{r global_options, class.source = 'hover-animate-background1', class.output = 'hover-animate-background2'}
## https://stackoverflow.com/a/36846793/3806250
options(width = 999)
knitr::opts_chunk$set(class.source = 'hover-animate-background1', class.output = 'hover-animate-background2', class.error = 'bg-danger')
```

<br><br>

# å—è¬›ç”Ÿã«ã‚ˆã‚‹ãƒ†ã‚¹ãƒˆï¼šMarkov chain Monte Carlo algorithms for Mixture Models

ä»–ã®å—è¬›ç”Ÿã®èª²é¡Œã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹

èª²é¡Œã®æå‡ºã€ãŠç–²ã‚Œã•ã¾ã§ã—ãŸï¼ã“ã‚Œã§ã€ä»–ã®å—è¬›ç”ŸãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ãã¾ã™ã€‚æˆç¸¾ã‚’å—ã‘å–ã‚‹ã«ã¯ã€ä»–ã®å—è¬›ç”Ÿã®èª²é¡Œã‚‚ã„ãã¤ã‹ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ æˆç¸¾ã¯`5æœˆ27æ—¥ 15:59 JST`ã¾ã§ã«å—ã‘å–ã‚Œã‚‹ã§ã—ã‚‡ã†ã€‚

<br><br>

## èª¬æ˜

Data on the lifetime (in years) of fuses produced by the ACME Corporation is available in the file `fuses.csv`:

In order to characterize the distribution of the lifetimes, it seems reasonable to fit to the data a two-component mixture of the form:
$$
\begin{align}
f(x) = w \lambda \exp\left\{ -\lambda x \right\} + (1-w)  \frac{1}{\sqrt{2\pi} \tau x} \exp\left\{ - \frac{1}{2 \tau^2} \left( \log(x) - \mu \right)^2\right\} \\ \quad\quad\quad x>0.
\end{align}
$$
The first component, which corresponds to an exponential distribution with rate $\lambda$, is used to model low-quality components with a very short lifetime. The second component, which corresponds to a [log-Gaussian distribution](https://en.wikipedia.org/wiki/Log-normal_distribution), is used to model normal, properly-functioning components.

You are asked to modify the implementation of the MCMC algorithm contained in the Reading "Sample code for MCMC example 1" so that you can fit this two-component mixture distributions instead. You then should run your algorithm for 10,000 iterations after a burn-in period of 1,000 iterations and report your estimates of the posterior means, rounded to two decimal places. Assume the following priors: $\omegaâˆ¼Uni[0,1], \lambdaâˆ¼Exp(1), \muâˆ¼Normal(0,1) $ and $\tau^2âˆ¼IGam(2,1)$.

<br><br>

### Review criteria

The code you generate should follow the same structure as "Sample code for MCMC example 1". In particular, focus on a Gibss sampler that alternates between the full conditionals for $\omega$, $\lambda$, $\mu$, $\tau^2$ and the latent component indicators $c_1, \ldots,c_n$. Peer reviewers will be asked to check whether the different pieces of code have been adequately modified to reflect the fact that (1) parameters have been initialized in a reasonable way, (2) each of the two full conditional distributions associated with the sampler are correct, and (2) the numerical values that you obtain are correct.  To simplify the peer-review process, assume that component 1 corresponds to the exponential distribution, while component 2 corresponds to the log-Gaussian distribution.

<br><br>

## è‡ªåˆ†ã®æå‡ºç‰©

## ãƒ”ã‚¢ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³

### Setup

```{r setup, warning = FALSE, message = FALSE}
if(!suppressPackageStartupMessages(require('BBmisc'))) {
  install.packages('BBmisc', dependencies = TRUE, INSTALL_opts = '--no-lock')
}
suppressPackageStartupMessages(require('BBmisc'))
# suppressPackageStartupMessages(require('rmsfuns'))

pkgs <- c('devtools', 'knitr', 'kableExtra', 'tidyr', 
          'readr', 'lubridate', 'data.table', 'reprex', 
          'timetk', 'plyr', 'dplyr', 'stringr', 'magrittr', 
          'tdplyr', 'tidyverse', 'formattable', 
          'echarts4r', 'paletteer')

suppressAll(lib(pkgs))
# load_pkg(pkgs)

## Set the timezone but not change the datetime
Sys.setenv(TZ = 'Asia/Tokyo')
## options(knitr.table.format = 'html') will set all kableExtra tables to be 'html', otherwise need to set the parameter on every single table.
options(warn = -1, knitr.table.format = 'html')#, digits.secs = 6)

## https://stackoverflow.com/questions/39417003/long-vectors-not-supported-yet-abnor-in-rmd-but-not-in-r-script
knitr::opts_chunk$set(message = FALSE, warning = FALSE)#, 
                      #cache = TRUE, cache.lazy = FALSE)

rm(pkgs)
```

```{r error = TRUE}
dat <- fread('data/fuses.csv') %>% as.matrix
head(dat)
```

<span style='color:green;'>*Source : `r paste(dim(dat), collapse = ' x ')`*</span>

### Assignment

```{r}
## Load package
if(!suppressPackageStartupMessages(require('rinvgamma'))) {
  ##install.packages('rinvgamma', dependencies = TRUE, INSTALL_opts = '--no-lock')
  devtools::install_github("dkahle/invgamma")
}
suppressPackageStartupMessages(require('rinvgamma'))

dat = fread('data/fuses.csv') 
fuses = dat$V1
logfuses = log(fuses)

## Initialize the parameters
KK         = 2                               # number of components
n = length(fuses)                         # number of samples
v = array(0, dim=c(n,KK))
v[,1] = 0.5                    #Assign half weight to first component
v[,2] = 1-v[,1]                #Assign all of the remaining weights to the second component
mean1 = sum(v[,1]*fuses)/sum(v[, 1]) #mean of the first component
lambda = 1.0/mean1            #parameter for the first component
mu = sum(v[,2]*logfuses)/sum(v[,2])    #parameter (mean) of the second component
sigmasquared = sum(v[,2]*((logfuses-mu)**2))/sum(v[,2]) #parameter (variance) for the second component
sigma = sqrt(sigmasquared)
w = mean(v[,1])
#print(paste(lambda, mu, tausquared, tau, w))
#print(paste(lambda, mu, sigmasquared, sigma, w))
paste(lambda, mu, sigmasquared, sigma, w)

# Priors
aa  = rep(1,KK)  # Uniform prior on 
# conjugate prior for exponential:
alpha = 2 #For Gamma distribution prior number of obs = alpha-1
beta = 1 #Sum of observations = beta
# conjugate prior for the normal
eta = mu          # Mean for the prior on mu
tau = 5          # Standard deviation 5 on the prior for mu_l
dd  = 2          # variance prior
qq  = 1

# Number of iterations of the sampler
rrr   = 6000
burn  = 1000

# Storing the samples
cc.out    = array(0, dim=c(rrr, n))
w.out     = rep(0, rrr)
lambda.out = rep(0,rrr)
mu.out    = array(0, rrr)
sigma.out = rep(0, rrr)
logpost   = rep(0, rrr)

# MCMC iterations
for(s in 1:rrr){
  # Sample the indicators
  cc = rep(0,n)
  for(i in 1:n){
    v = rep(0,KK)
    v[1] = log(w) + dexp(fuses[i], lambda, log=TRUE)  #Compute the log of the weights
    v[2] = log(1-w) + dnorm(logfuses[i], mu, sigma, log=TRUE)  #Compute the log of the weights
    v = exp(v - max(v))/sum(exp(v - max(v)))
    cc[i] = sample(1:KK, 1, replace=TRUE, prob=v)
  }
  
  # Sample the weights
  w = rbeta(1, aa[1] + sum(cc==1), aa[2] + sum(cc==2))
  
  # Sample the lambda
  nk    = sum(cc==1)
  xsumk = sum(fuses[cc==1])
  alpha.hat = alpha + nk
  beta.hat = beta + xsumk
  lambda = rgamma(1, shape = alpha.hat, rate = beta.hat)
  
  # Sample mu, the mean for norm
  nk    = sum(cc==2)
  xsumk = sum(logfuses[cc==2])
  tau2.hat = 1/(nk/sigma^2 + 1/tau^2)
  mu.hat  = tau2.hat*(xsumk/sigma^2 + eta/tau^2)
  mu   = rnorm(1, mu.hat, sqrt(tau2.hat))
  
  # Sample the variances
  dd.star = dd + nk/2
  qq.star = qq
  for(i in 1:n) {
    if (cc[i]==2) {
      qq.star = qq.star + ((logfuses[i] - mu)^2)/2
    }
  }
  sigma = sqrt(invgamma::rinvgamma(1, dd.star, qq.star))
  
  # Store samples
  cc.out[s,]    = cc
  w.out[s]     = w
  lambda.out[s] = lambda
  mu.out[s]    = mu
  sigma.out[s] = sigma
  
  
  for(i in 1:n){
    if(cc[i]==1){
      logpost[s] = logpost[s] + log(w) + dexp(fuses[i], lambda, log=TRUE)
    }else{
      logpost[s] = logpost[s] + log(1-w) + dnorm(logfuses[i], mu, sigma, log=TRUE)
    }
  }
  logpost[s] = logpost[s] + dbeta(w, aa[1], aa[2],log = T)
  logpost[s] = logpost[s] + dgamma(lambda, shape = alpha, rate = beta, log = T)
  logpost[s] = logpost[s] + dnorm(mu, eta, tau, log = T)
  logpost[s] = logpost[s] + log(invgamma::dinvgamma(sigma^2, dd, 1/qq))
  
  if(s/500==floor(s/500)){
    print(paste("s =",s, w, lambda, mu, sigma, logpost[s]))
  }
}

## Plot the logposterior distribution for various samples
par(mfrow=c(1,1))
par(mar=c(4,4,1,1)+0.1)
plot(logpost, type="l", xlab="Iterations", ylab="Log posterior")

w_avg = sum(w.out[(burn+1):rrr])/(rrr-burn)
lambda_avg = sum(lambda.out[(burn+1):rrr])/(rrr-burn)
mu_avg = sum(mu.out[(burn+1):rrr])/(rrr-burn)
sigma_avg = sum(sigma.out[(burn+1):rrr])/(rrr-burn)

#print(paste(w_avg, lambda_avg, mu_avg, sigma_avg))
paste(w_avg, lambda_avg, mu_avg, sigma_avg)

w_sum = 0
lambda_sum = 0
mu_sum = 0
sigma_sum = 0
counter = 0
for(s in 1:(rrr-burn)){
  w_sum = w_sum + w.out[s+burn]
  lambda_sum = lambda_sum + lambda.out[s+burn]
  mu_sum = mu_sum +mu.out[s+burn]
  sigma_sum = sigma_sum + sigma.out[s+burn]
  counter = counter + 1
}

#print(paste(counter, w_sum/counter, lambda_sum/counter, mu_sum/counter, sigma_sum/counter))
paste(counter, w_sum/counter, lambda_sum/counter, mu_sum/counter, sigma_sum/counter)
```

<br><br>

## ãƒ¬ãƒ“ãƒ¥ãƒ¼

### 1st Peer


<br><br>

### 2nd Peer


<br><br>

### 3rd Peer


<br><br>

## ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³

<br><br>

# Appendix

## Blooper

## Documenting File Creation 

It's useful to record some information about how your file was created.

- File creation date: 2021-05-12
- File latest updated date: `r today('Asia/Tokyo')`
- `r R.version.string`
- [**rmarkdown** package](https://github.com/rstudio/rmarkdown) version: `r packageVersion('rmarkdown')`
- File version: 1.0.0
- Author Profile: [Â®Î³Ïƒ, Eng Lian Hu](https://github.com/scibrokes/owner)
- GitHub: [Source Code](https://github.com/englianhu/coursera-bayesian-statistics-mixture-models)
- Additional session information:

```{r info, warning = FALSE, results = 'asis'}
suppressMessages(require('dplyr', quietly = TRUE))
suppressMessages(require('magrittr', quietly = TRUE))
suppressMessages(require('formattable', quietly = TRUE))
suppressMessages(require('knitr', quietly = TRUE))
suppressMessages(require('kableExtra', quietly = TRUE))

sys1 <- devtools::session_info()$platform %>% 
  unlist %>% data.frame(Category = names(.), session_info = .)
rownames(sys1) <- NULL

sys2 <- data.frame(Sys.info()) %>% 
  dplyr::mutate(Category = rownames(.)) %>% .[2:1]
names(sys2)[2] <- c('Sys.info')
rownames(sys2) <- NULL

if (nrow(sys1) == 9 & nrow(sys2) == 8) {
  sys2 %<>% rbind(., data.frame(
  Category = 'Current time', 
  Sys.info = paste(as.character(lubridate::now('Asia/Tokyo')), 'JSTğŸ—¾')))
} else {
  sys1 %<>% rbind(., data.frame(
  Category = 'Current time', 
  session_info = paste(as.character(lubridate::now('Asia/Tokyo')), 'JSTğŸ—¾')))
}

sys <- cbind(sys1, sys2) %>% 
  kbl(caption = 'Additional session information:') %>% 
  kable_styling(bootstrap_options = c('striped', 'hover', 'condensed', 'responsive')) %>% 
  row_spec(0, background = 'DimGrey', color = 'yellow') %>% 
  column_spec(1, background = 'CornflowerBlue', color = 'red') %>% 
  column_spec(2, background = 'grey', color = 'black') %>% 
  column_spec(3, background = 'CornflowerBlue', color = 'blue') %>% 
  column_spec(4, background = 'grey', color = 'white') %>% 
  row_spec(9, bold = T, color = 'yellow', background = '#D7261E')

rm(sys1, sys2)
sys
```

## Reference

- [Bayesian Statistics: Mixture Models (Assessment 2 Codes)](https://rpubs.com/englianhu/767588)
- [Global CSS settings, fundamental HTML elements styled and enhanced with extensible classes, and an advanced grid system](https://getbootstrap.com/docs/3.3/css/#helper-classes-backgrounds)
- [Chunk option class.output is not working on Error Message](https://stackoverflow.com/a/55006240/3806250)
- [Width of R code chunk output in RMarkdown files knitr-ed to html](https://stackoverflow.com/a/36846864/3806250)
- [CodePen Home MathJax scale to fit container](https://codepen.io/mathjax/pen/qEdqPg)
- [align, aligned and R Markdown](https://tex.stackexchange.com/questions/284538/align-aligned-and-r-markdown)
- [**FR***: MathJax scale to fit container #2135](https://github.com/rstudio/rmarkdown/issues/2135)
- [rmarkdown-book/03-documents.Rmd : MathJax equations](https://github.com/rstudio/rmarkdown-book/blob/master/03-documents.Rmd)
- [Plot in R with `echarts4r`](https://www.infoworld.com/article/3607068/plot-in-r-with-echarts4r.html)
- [`echarts` : Theme Builder](https://echarts.apache.org/en/theme-builder.html)
- [Sample Code for EM Example 1](https://github.com/englianhu/Coursera-Bayesian-Statistics-Mixture-Models/blob/main/Sample-Code-for%20EM-EX1.R)

<br><br>
