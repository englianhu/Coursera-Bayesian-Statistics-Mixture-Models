# Computational considerations for Mixture Models

合計点数 3

1. 質問 1

Consider a mixture of three Gaussian distribution with common identity covariance matrix and means $\mu_1 = (0,0)'$, $\mu_2 = (1/3,1/3)'$ and \mu_3 = (-2/3,1/3)'.

For an observation $x_i = (31,-23)'$, what is the value of $v_{i,2}$, the probability of the observation being generated by the second component (rounded to three decimal places)? (1点)

- 0.928 正解
- 1.00
- 0.072

正解
This is correct. The following code computes the value of interest.  Note that the calculations have been done in the log-likelihood scale.  Working in the original likelihood scale in this case leads to a wrong answer rather than an error.

```{r}
library(mvtnorm)

mu1 = c(0, 0)
mu2 = c(1/3, 1/3)
mu3 = c(-2/3, 1/3)
x = c(31, -23)
Sigma = diag(1,2)

l1 = dmvnorm(x, mu1, Sigma, log=T)
l2 = dmvnorm(x, mu2, Sigma, log=T)
l3 = dmvnorm(x, mu3, Sigma, log=T)

exp(l2 - max(l1,l2,l3))/(exp(l1 - max(l1,l2,l3)) + exp(l2 - max(l1,l2,l3)) + exp(l3 - max(l1,l2,l3)))
```

2. 質問 2

True or False: The starting value for the parameters of the mixture model in the EM algorithm could have an impact on the solution you obtain. (1点)

- True 正解
- False

正解
The likelihood function for the mixture model is typically multimodal, something we have illustrated in the lectures various times.  Since the EM algorithm only guaranties convergence to a local mode, the initial value could have an effect on the solution that will not vanish no matter how long you run the algorithm.


3. 質問 3

True or False: Consider a Bayesian formulation of a Mixture Model that uses informative priors for all the parameters.  A Markov chain Monte Carlo (MCMC) algorithm for fitting such model will fail to work if no observations are allocated to a component of the mixture. (1点)

- True 不正解
- False

不正解
Because the priors are proper, a well-implemented MCMC algorithm should not fail under this circumstances.  This is in contrast to an EM algorithm, where very small values of $v_{i,k}$ for a given $k$ and all $i$ might lead the algorithm to fail, as we demonstrated in the lecture.

